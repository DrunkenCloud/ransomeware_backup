{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d67d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Binarize for ROC AUC (since it's multiclass)\n",
    "y_binarized = label_binarize(y, classes=[0, 1, 2])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test, yb_train, yb_test = train_test_split(\n",
    "    X, y, y_binarized, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a493cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Only use the classes present in y_test\n",
    "    yb_test = label_binarize(y_test, classes=np.unique(y_test))\n",
    "    auc = roc_auc_score(yb_test, y_prob, multi_class='ovr')\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd46ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.96      0.94      0.95        50\n",
      "           2       0.96      1.00      0.98        47\n",
      "           3       0.98      0.96      0.97        54\n",
      "           4       1.00      0.97      0.98        60\n",
      "           5       0.94      0.95      0.95        66\n",
      "           6       0.96      0.98      0.97        53\n",
      "           7       1.00      0.96      0.98        55\n",
      "           8       0.91      0.98      0.94        43\n",
      "           9       0.97      0.95      0.96        59\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n",
      "AUC: 0.9991\n",
      "\n",
      "--- KNN ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.98      1.00      0.99        50\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       0.98      1.00      0.99        54\n",
      "           4       0.98      1.00      0.99        60\n",
      "           5       0.99      1.00      0.99        66\n",
      "           6       1.00      1.00      1.00        53\n",
      "           7       1.00      0.98      0.99        55\n",
      "           8       0.98      0.98      0.98        43\n",
      "           9       0.98      0.93      0.96        59\n",
      "\n",
      "    accuracy                           0.99       540\n",
      "   macro avg       0.99      0.99      0.99       540\n",
      "weighted avg       0.99      0.99      0.99       540\n",
      "\n",
      "AUC: 0.9981\n",
      "\n",
      "--- Decision Tree ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        53\n",
      "           1       0.74      0.78      0.76        50\n",
      "           2       0.83      0.74      0.79        47\n",
      "           3       0.78      0.85      0.81        54\n",
      "           4       0.81      0.85      0.83        60\n",
      "           5       0.92      0.86      0.89        66\n",
      "           6       0.93      0.94      0.93        53\n",
      "           7       0.85      0.84      0.84        55\n",
      "           8       0.89      0.77      0.82        43\n",
      "           9       0.78      0.85      0.81        59\n",
      "\n",
      "    accuracy                           0.84       540\n",
      "   macro avg       0.85      0.84      0.84       540\n",
      "weighted avg       0.85      0.84      0.84       540\n",
      "\n",
      "AUC: 0.9108\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(max_iter=200)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf3 = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "auc1 = evaluate_model(\"Logistic Regression\", clf1, X_train, X_test, y_train, y_test)\n",
    "auc2 = evaluate_model(\"KNN\", clf2, X_train, X_test, y_train, y_test)\n",
    "auc3 = evaluate_model(\"Decision Tree\", clf3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52d39a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Voting Classifier ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.98      0.98      0.98        50\n",
      "           2       0.98      1.00      0.99        47\n",
      "           3       0.98      0.98      0.98        54\n",
      "           4       0.98      1.00      0.99        60\n",
      "           5       1.00      0.95      0.98        66\n",
      "           6       0.96      0.98      0.97        53\n",
      "           7       0.96      0.98      0.97        55\n",
      "           8       1.00      0.98      0.99        43\n",
      "           9       0.97      0.97      0.97        59\n",
      "\n",
      "    accuracy                           0.98       540\n",
      "   macro avg       0.98      0.98      0.98       540\n",
      "weighted avg       0.98      0.98      0.98       540\n",
      "\n",
      "AUC: 0.9996\n",
      "\n",
      "--- Performance Comparison ---\n",
      "Best Individual AUC: 0.9991\n",
      "Voting Classifier AUC: 0.9996\n",
      "✅ Voting Classifier outperformed the individual models.\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('knn', clf2), ('dt', clf3)],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "y_prob = voting_clf.predict_proba(X_test)\n",
    "\n",
    "yb_test = label_binarize(y_test, classes=np.unique(y_test))\n",
    "\n",
    "print(\"\\n--- Voting Classifier ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "auc_voting = roc_auc_score(yb_test, y_prob, multi_class='ovr')\n",
    "print(f\"AUC: {auc_voting:.4f}\")\n",
    "\n",
    "best_individual_auc = max(auc1, auc2, auc3)\n",
    "print(\"\\n--- Performance Comparison ---\")\n",
    "print(f\"Best Individual AUC: {best_individual_auc:.4f}\")\n",
    "print(f\"Voting Classifier AUC: {auc_voting:.4f}\")\n",
    "if auc_voting > best_individual_auc:\n",
    "    print(\"✅ Voting Classifier outperformed the individual models.\")\n",
    "else:\n",
    "    print(\"⚠️ Voting Classifier did not outperform the best individual model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
